---
title: "tourr; visualizing higher dimensions vs alternatives"
author: "NS Spyrison"
date: "July 2018"
output: 
  html_document:
   self_contained: no
---
#**NOTE: Graphics of tourr::animate make it to the figures folder, but not into the .html document!!**


```{r setup, include=FALSE}
knitr::opts_chunk$set(
  echo       = FALSE,  #code
  include    = TRUE,   #plots
  results    = "hide", #text
  message    = FALSE,  #messages
  warning    = FALSE,  #warnings
  error      = FALSE,  #errors
  collapse   = TRUE,
  #comment    = "",
  #fig.height = 8,
  #fig.width  = 12,
  fig.align  = "center",
  cache      = FALSE
)

library(tourr)
library(ggplot2)
library(magrittr)
library(gridExtra)
library(Rtsne)
```



## Absract
Visualizing in higher (greater than p=3 numeric dimensions) can be messy and unintuitive. Here we compare and contrast different methodolgy; namely Principal Component Analysis (PCA, 1901 K. Person), T-distributed Stochastic Neighbor Embedding (t-SNE, 2008 L van derMaaten & G Hinton), and Projection Pursuit (PP, 1974 J Friedman & J Tukey)

The R package, tourr (2011, H Wickham & D Cook), gives a means to animate 2-d projections of rotated p-dimensional data object. The path of rotation may take the form of a random walk (Grand Tour, 1985 D Asimov), predefined path, or optimizing an index by some stochastic gradient descent (Projection Pursuit, described above). 
<!-- Parallel Coordinate Plot, (PCP 1885 P. d'Ocagne) -->

### Data set - flea
Consists of 74 observations of 6 length measurements taken across 3 different species of flea-beetles. Within the graphics species is used to select color and point character, but the methods are discused are all unsupervized (they can't use species). Data from A Lubischew (1962), Analogous to R Fisher's Iris data [100x5] (1936). The flea dataset is available in the `tourr` and `spinifex` R packages.
<!-- Other sets to know Iris, MNIST -->


### Goal intuition
**Find the best way to visualize 3 speices as seprate, given 6 dimensions of data.** 

## Principal Component Analysis, PCA
Let's start with the tried and true technique of Principal Component Analysis (aka eigen value decomposition, singular value decomposition, and many other names). PCA gives a linear comination of variables (or a map) from {$x, y, ..., p$}-space to {$pc_1, pc_2, ... pc_p$}-space with $pc_1$ pointing in the direction of most variance (by convention), $pc_2$ is at a right angle to $pc_1$ and give the direction with the next most variation and so on. It's worth noting that PCA acheives the global optimization (same answer every time). 

Notice PCA is still in a p-dimensional space, so **where does the dim reduction come in?** Making use of the now ordered dims plot the first 2 PC,a 2-dim scatterplot, the most variation we can explain with 2-dim. Below we use the R package `stats`, included in the standard R installation.

```{r, eval=FALSE, echo=TRUE}
f.pca <- stats::prcomp(flea)
ggplot2::ggplot(f.pca) + ...
```
```{r}
### PCA
f <- flea[, 1:6]
f.pca <- stats::prcomp(f, center = TRUE, scale. = TRUE)

dat <- as.data.frame(f.pca$x) %>% cbind("Species" = flea[,7])
(gg3 <- ggplot(dat, aes(x = PC1, y = PC2, shape = Species, col = Species)) +
  geom_point(size = 3) + ggtitle("PC1 by PC2") + 
  theme(legend.position = c(.945, .88), 
        legend.background=element_rect(colour ="darkgray")
  ) + coord_fixed()
)
```

**What about the remaining dimensions?** That is the accepted loss of only looking at the first 2 PC. Let's look see how much it costs.

```{r}
dat <- as.data.frame(cbind("PC"=1:6,
                     "Var"=f.pca$sdev, 
                     "Prop_Var"= f.pca$sdev/sum(f.pca$sdev),
                     "cumsum_Prop_Var"= cumsum(f.pca$sdev)/sum(f.pca$sdev)
                     ) )
gg1 <- ggplot(dat,aes(x=PC,y=Prop_Var,label=round(Prop_Var,3))) + 
  geom_point(size = 3) + geom_line() + ggtitle("~pmf, prop of explain Var") + 
  geom_text(nudge_x = 0.3, nudge_y = .01) +
  geom_ribbon(data=dat[-1, ], aes(x=PC, ymin=0, ymax=Prop_Var), 
              fill = "red", alpha = .2) 
gg2 <- ggplot(dat,aes(x=PC,y=cumsum_Prop_Var,label=round(cumsum_Prop_Var,3))) +
  geom_point(size = 3) + geom_line() + ggtitle("~cmf, cummulative prop of expalined Var") + 
  geom_text(nudge_x = 0.3, nudge_y = -.015) +
  geom_ribbon(data=dat[-1, ], aes(x=PC, ymin=cumsum_Prop_Var, ymax=1), 
              fill = "red", alpha = .2)
gridExtra::grid.arrange(gg1, gg2, ncol = 2)
```

We have **lost over 40% of the variation explained** in 6-dim, but looking at the 2-dim proximation.


##  t-distributed Stochastic Neighbor Embedding, t-SNE
Contrast with t-SNE, a popular contemporary technique. In short, t-SNE is a non-linear transformation of {$x, y, ... p$}-space that optimizes seperating clusters while preserving local structure. 

**Imagine a map that can be photoshoped to show all cities as seprate entities without letting cities merge or split.** In this sort of photoshop can zoom, rotate, distort, and move geological features and distances. This might be a good way to describe where and how neighboring cities are different, but it not usful as a road map. t-SNE is a local optimization, with very low reproducability (little chance seprate photoshops turn out exactly the same)

We apply the R package `tsne`. t-SNE returns p, unordered dimensions. Order them with PCA and view in 2 dimensions.

```{r, eval=FALSE, echo=TRUE}
f.tsne <- Rtsne(f, ...)
f.tsne.pca <- stats::prcomp(f.tsne)
ggplot2::ggplot(f.tsne.pca) + ...
```
```{r}
### t-SNE
#perplexity is knn. ~.9 sec for [74x6]
f.tsne <- Rtsne(f, dims = 6, perplexity=15, verbose=TRUE, max_iter = 500) 
colnames(f.tsne$Y) <- paste0("tS",1:6)
# t-SNE is not inherently ordered, so let's do PCA on it.

f.tsne.pca <- stats::prcomp(f.tsne$Y, center = TRUE, scale. = TRUE)
colnames(f.tsne.pca$x) <- paste0("tSNE_PC",1:6)
dat <- as.data.frame(f.tsne.pca$x) %>% cbind("Species" = flea[,7])
(gg4 <- ggplot(dat, aes(x = tSNE_PC1, y = tSNE_PC2, 
                        shape = Species, col = Species)) +
  geom_point(size = 3) + ggtitle("t-SNE PC1 by PC2") + 
  theme(legend.position = c(.945, .88), 
        legend.background=element_rect(colour ="darkgray")
  ) + coord_fixed()
)
```

Wow, much more distinct groups than PCA. **So why bother using PCA?** t-SNE can give impressive visuals, but can overfit datasets (find clusters from random noise). Worse yet is t-SNE is a non-linear transformation (photoshopable) we lose the interprbility back to the original dimensions, a non-starter for analysis.


## Projection pursuit, PP
The 3rd method we'll discuss is holes-optimized projection pursuit. This is a (stochastic) gradient descent optimizing for space between points around the center of the data.

This can be imagined as climbing a mountain with low visability. Akin to many repetitions of: checking for higher ground. If you find any, walk there and check again until you don't see any higher point. In our analogy finding higher ground corrisponds to finding a small rotation that gives us slightly more space between the middle points.

This is a local optimization, but is much more restrained than t-SNE (there are relatively few mountain peaks in a mountain range as compared with ways to photoshop a map). We perform a holes opimtimization via the R package `tourr`

```{r, eval=FALSE, echo=TRUE}
tourr::animate_xy(flea, guided_tour(index = holes))
```
```{r}
### Tourr
library(tourr)
f.col <- rainbow(length(unique(flea$species)))[as.numeric(as.factor(flea$species))]
f.pch <- as.numeric(flea$species)+14

f.holes <- save_history(f, guided_tour(index = holes), max_bases = 25)
f.holes_end <- matrix(as.numeric(f.holes[,,dim(f.holes)[3]]),ncol=2)

dat <- as.data.frame(scale(as.matrix(f), center=T, scale=T) %*% f.holes_end)
colnames(dat) <- c("x", "y")
dat %<>% cbind("Species" = flea[,7])
(gg5 <- ggplot(dat, aes(x = x, y = y, 
                        shape = Species, col = Species)) +
  geom_point(size = 3) + ggtitle("Holes index projection pursuit") + 
  theme(legend.position = c(.945, .88), 
        legend.background=element_rect(colour ="darkgray")
  ) + coord_fixed()
)
```

Typically close to PCA or an isomorphism of it.

### References
H. Wickham, D. Cook, and H. Hofmann (2015). Visualising statistical models: Removing the blindfold (withdiscussion). Statistical Analysis and Data Mining 8(4), 203–225.

H. Wickham, D. Cook, H. Hofmann, and A. Buja (2011). tourr: An r package for exploring multivariate data with projections. Journal of Statistical Software 40(2), http://www.jstatsoft.org/v40.

G Grinstein, M Trutschl, & U Cvek (2002). High-Dimensional Visualizations. psu.edu.

### Other reading
[Principal Component Analysis](https://en.wikipedia.org/wiki/Principal_component_analysis)

[t-distributed Stochastic Neighbor Embedding](https://en.wikipedia.org/wiki/T-distributed_stochastic_neighbor_embedding)

[Projection pursuit](https://en.wikipedia.org/wiki/Projection_pursuit)

[Grand Tour](https://en.wikipedia.org/wiki/Grand_Tour_(data_visualisation))


<!-- Asimov D (1985). “The Grand Tour: A Tool for Viewing Multidimensional Data.” SIAM -->
<!-- Journal of Scientific and Statistical Computing, 6(1), 128–143. -->

## Apendix

#INCLUDE HOLE TOUR, 50 SLIDE OF GRAND TOUR, and SPINIFEX.

#### Methodology side-by-side
```{r}
#### Methodology side-by-side
gridExtra::grid.arrange(gg3, gg4, gg5, ncol = 3)
```

#### PC inititialization and holes index
```{r}
#### PC inititialization and holes index
f.pca <- prcomp(f, center = TRUE, scale. = TRUE)
f.pca.holes <- save_history(f.pca$x, guided_tour(index = holes), max_bases = 25)
f.pca.holes_end <- matrix(as.numeric(f.pca.holes[,,dim(f.pca.holes)[3]]),ncol=2)

#show that PCA gives us a good starting orientation for projection pursuit.
##NEED TO FIX THIS!!!
par(mfrow=c(1,3))
animate(f.pca$x, start=f.pca.holes_end, max_frames=0,
        display=display_xy(pch=20, col=f.col))
title(main="PCA", line=1)
animate(f.pca$x, start=f.pca.holes_end, max_frames=0,
        display=display_xy(pch=20, col=f.col))
title(main="PCI holes tour", line=1)
animate(f, start=f.pca.holes_end, max_frames=0,
        display = display_xy(pch=20, col=f.col))
title(main="non-PCI holes tour", line=1)
par(mfrow=c(1,1))
```

#### MVN Noise
```{r}
#### RANDOM NOISE:
mvn <- matrix(rnorm(900),nrow=100,ncol=9)
colnames(mvn) <- paste0("n",1:9)
#pca
mvn.pca <- prcomp(mvn, center = TRUE, scale. = TRUE)
mvn.v = round(sum(mvn.pca[[1]][1:2]) / sum(mvn.pca[[1]]),3) 
mvn.main = paste(100*mvn.v,"% of var~ PC1,2")
#tour
mvn.holes <- save_history(mvn, guided_tour(index = holes), max_bases = 25)
mvn.holes_end <- matrix(as.numeric(mvn.holes[,,dim(mvn.holes)[3]]),ncol=2)
#t-sne
mvn.tsne <- Rtsne(mvn, dims = 9, perplexity=15, verbose=TRUE, max_iter = 500)
colnames(mvn.tsne$Y) <- paste0("tS",1:9)

## MVN method compare
par(mfrow=c(1,3))
animate(mvn.pca$x, max_frames=0, 
        display = display_xy(pch=20))
title(main="PCA1,2", line=1)
animate(mvn.tsne$Y, max_frames=0, 
        display = display_xy(pch=20))
title(main="t-SNE1,2", line=1)
animate(mvn, start=mvn.holes_end, max_frames=0,
        display = display_xy(pch=20))
title(main="holes tour", line=1)
par(mfrow=c(1,1))
```

#### non reproducability of t-SNE
```{r}
#### non reproducability of t-SNE
set.seed(1)
par(mfrow=c(3,3))
for (i in 1:9) {
  f.tsne <- Rtsne(f, dims = 6, perplexity=15, verbose=TRUE, max_iter = 500)
  colnames(f.tsne$Y) <- paste0("tS",1:6)
  plot(f.tsne$Y, col=f.col, pch=f.pch, xaxt='n', yaxt='n', ann=FALSE)
  title(main=paste("t-SNE ",i))
}
par(mfrow=c(1,1))
```

